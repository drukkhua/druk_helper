"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π AI —Å–µ—Ä–≤–∏—Å —Å –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø—Ä–æ–º–ø—Ç–∞–º–∏
–†–∞—Å—à–∏—Ä—è–µ—Ç –±–∞–∑–æ–≤—ã–π AIService —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ "–û–ª–µ–Ω–∞"
"""

import logging
import asyncio
import time
from typing import Dict, Optional

try:
    import openai
    from openai import AsyncOpenAI
except ImportError:
    openai = None
    AsyncOpenAI = None

from src.core.business_hours import is_business_time
from src.ai.knowledge_base import knowledge_base
from src.ai.enhanced_rag_service import enhanced_rag_service
from src.ai.conversation_memory import conversation_memory
from src.analytics.analytics_service import analytics_service
from src.managers.models import unified_db
from config import Config

logger = logging.getLogger(__name__)


class EnhancedAIService:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π AI —Å–µ—Ä–≤–∏—Å —Å –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–µ–π"""

    def __init__(self):
        self.config = Config()
        self.enabled = self.config.AI_ENABLED
        self.fallback_to_templates = self.config.AI_FALLBACK_TO_TEMPLATES

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞
        self.openai_client: Optional[AsyncOpenAI] = None
        self.use_real_ai = False

        if self.enabled and openai and self.config.OPENAI_API_KEY:
            try:
                self.openai_client = AsyncOpenAI(api_key=self.config.OPENAI_API_KEY, timeout=30.0)
                self.use_real_ai = True
                logger.info("Enhanced AI Service –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å —Ä–µ–∞–ª—å–Ω—ã–º OpenAI API")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ OpenAI: {e}")
                self.use_real_ai = False

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
        self.knowledge_base = knowledge_base
        self.enhanced_rag = enhanced_rag_service
        self.knowledge_ready = False

        if self.enabled:
            self._init_knowledge_base()
            mode = "REAL OpenAI" if self.use_real_ai else "MOCK"
            kb_status = (
                "with Enhanced Knowledge Base" if self.knowledge_ready else "without Knowledge Base"
            )
            logger.info(
                f"Enhanced AI Service –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –≤ —Ä–µ–∂–∏–º–µ: ENABLED ({mode}) {kb_status}"
            )
        else:
            logger.info("Enhanced AI Service –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –≤ —Ä–µ–∂–∏–º–µ: DISABLED")

    def _init_knowledge_base(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
        try:
            success = self.knowledge_base.populate_vector_store()
            if success:
                self.knowledge_ready = True
                stats = self.knowledge_base.get_statistics()
                logger.info(f"–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –≥–æ—Ç–æ–≤–∞: {stats.get('total_documents', 0)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            else:
                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –±–∞–∑—É –∑–Ω–∞–Ω–∏–π")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {e}")

    def is_available(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å AI —Å–µ—Ä–≤–∏—Å–∞"""
        if not self.enabled:
            return False

        if not self.use_real_ai:
            return True

        if not self.openai_client or not self.config.OPENAI_API_KEY:
            logger.warning("Enhanced AI Service –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: –ø—Ä–æ–±–ª–µ–º—ã —Å OpenAI API")
            return False

        return True

    async def process_query(self, user_query: str, user_id: int, language: str = "ukr") -> Dict:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–µ–π

        Args:
            user_query: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            language: –Ø–∑—ã–∫ –æ—Ç–≤–µ—Ç–∞

        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        start_time = time.time()

        try:
            # –õ–æ–≥–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏—Ç–∏–∫—É
            query_id = analytics_service.log_user_query(user_id, user_query, language)

            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –ø–∞–º—è—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
            conversation_memory.add_user_message(user_id, user_query, language)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å AI
            if not self.is_available():
                logger.warning("Enhanced AI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
                return await self._fallback_response(user_query, user_id, language)

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ —É–ª—É—á—à–µ–Ω–Ω—ã–π AI
            if self.use_real_ai:
                ai_result = await self._process_with_enhanced_openai(user_query, user_id, language)
            else:
                ai_result = await self._process_with_enhanced_mock(user_query, user_id, language)

            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –≤ –ø–∞–º—è—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
            conversation_memory.add_assistant_message(
                user_id,
                ai_result["answer"],
                metadata={
                    "confidence": ai_result["confidence"],
                    "source": ai_result["source"],
                    "persona_enhanced": True,
                    "language": language,
                },
            )

            # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            response_time_ms = int((time.time() - start_time) * 1000)
            analytics_service.log_ai_response(
                query_id,
                ai_result["answer"],
                ai_result["confidence"],
                ai_result["source"],
                response_time_ms=response_time_ms,
            )

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å
            follow_up = self.enhanced_rag.generate_follow_up_question(
                user_query, {"language": language, "user_id": user_id}
            )

            if follow_up:
                ai_result["answer"] += f"\n\n‚ùì {follow_up}"

            ai_result["response_time_ms"] = response_time_ms
            ai_result["enhanced"] = True

            return ai_result

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ (Enhanced): {e}")
            response_time_ms = int((time.time() - start_time) * 1000)

            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º fallback –æ—Ç–≤–µ—Ç
            return {
                "answer": (
                    "–í–∏–±–∞—á—Ç–µ, –≤–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞. –°–ø—Ä–æ–±—É–π—Ç–µ —â–µ —Ä–∞–∑ –∞–±–æ –∑–≤'—è–∂—ñ—Ç—å—Å—è –∑ –º–µ–Ω–µ–¥–∂–µ—Ä–æ–º."
                    if language == "ukr"
                    else "–ò–∑–≤–∏–Ω–∏—Ç–µ, –≤–æ–∑–Ω–∏–∫–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ —Å–≤—è–∂–∏—Ç–µ—Å—å —Å –º–µ–Ω–µ–¥–∂–µ—Ä–æ–º."
                ),
                "confidence": 0.0,
                "source": "error_fallback",
                "response_time_ms": response_time_ms,
                "enhanced": True,
                "error": str(e),
            }

    async def _process_with_enhanced_openai(
        self, user_query: str, user_id: int, language: str
    ) -> Dict:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ —Ä–µ–∞–ª—å–Ω—ã–π OpenAI —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –ø—Ä–æ–º–ø—Ç–∞–º–∏"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
            context = await self.enhanced_rag.get_context_for_query(user_query, language)

            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏
            user_context = await self._get_user_context(user_id, user_query)

            # –°–æ–∑–¥–∞–µ–º –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            system_prompt = self.enhanced_rag.create_enhanced_system_prompt(
                language, context, user_context
            )

            # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
            conversation_history = conversation_memory.get_conversation_context(
                user_id, max_messages=6
            )

            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è OpenAI
            messages = [{"role": "system", "content": system_prompt}]
            messages.extend(conversation_history)
            messages.append({"role": "user", "content": user_query})

            # –í—ã–∑—ã–≤–∞–µ–º OpenAI
            response = await self.openai_client.chat.completions.create(
                model=self.config.AI_MODEL,
                messages=messages,
                temperature=self.config.AI_TEMPERATURE,
                max_tokens=self.config.AI_MAX_TOKENS,
            )

            answer = response.choices[0].message.content.strip()

            # –£–ª—É—á—à–∞–µ–º –æ—Ç–≤–µ—Ç —Å —É—á–µ—Ç–æ–º –ø—Ä–µ–º–∏–∞–ª—å–Ω–æ–≥–æ —Ü–µ–Ω–æ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
            try:
                from PREMIUM_PRICING_ENHANCEMENT import enhance_ai_response_with_premium_pricing

                answer = enhance_ai_response_with_premium_pricing(answer, user_query, language)
            except ImportError:
                logger.warning("Premium pricing enhancement –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")

            # –î–æ–±–∞–≤–ª—è–µ–º —ç–º–æ–¥–∑–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
            if not any(emoji in answer for emoji in ["üî∏", "üìã", "üëï", "üìÑ", "üí∞", "‚è∞", "üòä", "üíô", "üéØ"]):
                answer = f"üòä {answer}"

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            confidence = self._calculate_enhanced_confidence(answer, context, user_query)

            logger.info(
                f"Enhanced OpenAI –æ—Ç–≤–µ—Ç –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {len(answer)} —Å–∏–º–≤–æ–ª–æ–≤, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.1%}"
            )

            return {
                "answer": answer,
                "confidence": confidence,
                "source": "enhanced_openai",
                "context_used": bool(context),
                "persona_name": "–û–ª–µ–Ω–∞",
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ Enhanced OpenAI: {e}")
            raise

    async def _process_with_enhanced_mock(
        self, user_query: str, user_id: int, language: str
    ) -> Dict:
        """Mock —Ä–µ–∂–∏–º —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –æ—Ç–≤–µ—Ç–∞–º–∏"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
            context = await self.enhanced_rag.get_context_for_query(user_query, language)

            if context:
                if language == "ukr":
                    base_answer = f"–û—Å—å —â–æ –º–æ–∂—É —Ä–æ–∑–ø–æ–≤—ñ—Å—Ç–∏ –∑ –¥–æ—Å–≤—ñ–¥—É:\n\n{context}"
                else:
                    base_answer = f"–í–æ—Ç —á—Ç–æ –º–æ–≥—É —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å –∏–∑ –æ–ø—ã—Ç–∞:\n\n{context}"
                confidence = 0.8
            else:
                if language == "ukr":
                    base_answer = "–ù–∞ –∂–∞–ª—å, –Ω–µ –º–∞—é —Ç–æ—á–Ω–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –∑ —Ü—å–æ–≥–æ –ø–∏—Ç–∞–Ω–Ω—è. –ó–≤'—è–∂—ñ—Ç—å—Å—è –∑ –Ω–∞—à–∏–º –º–µ–Ω–µ–¥–∂–µ—Ä–æ–º –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ—ó –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü—ñ—ó!"
                else:
                    base_answer = "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ –∏–º–µ—é —Ç–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É. –°–≤—è–∂–∏—Ç–µ—Å—å —Å –Ω–∞—à–∏–º –º–µ–Ω–µ–¥–∂–µ—Ä–æ–º –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏!"
                confidence = 0.3

            # –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
            user_context = await self._get_user_context(user_id, user_query)
            if user_context.get("is_returning_user"):
                if language == "ukr":
                    base_answer = f"–ü—Ä–∏–≤—ñ—Ç –∑–Ω–æ–≤—É! üòä –†–∞–¥–∏–π, —â–æ –ø–æ–≤–µ—Ä—Ç–∞—î—Ç–µ—Å—å.\n\n{base_answer}"
                else:
                    base_answer = f"–ü—Ä–∏–≤–µ—Ç —Å–Ω–æ–≤–∞! üòä –†–∞–¥–∞, —á—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç–µ—Å—å.\n\n{base_answer}"

            # –£–ª—É—á—à–∞–µ–º –æ—Ç–≤–µ—Ç —Å —É—á–µ—Ç–æ–º –ø—Ä–µ–º–∏–∞–ª—å–Ω–æ–≥–æ —Ü–µ–Ω–æ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
            try:
                from PREMIUM_PRICING_ENHANCEMENT import enhance_ai_response_with_premium_pricing

                base_answer = enhance_ai_response_with_premium_pricing(
                    base_answer, user_query, language
                )
            except ImportError:
                logger.warning("Premium pricing enhancement –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")

            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥–ø–∏—Å—å –û–ª–µ–Ω—ã
            if language == "ukr":
                base_answer += "\n\nüíô –ó –ø–æ–≤–∞–≥–æ—é, –û–ª–µ–Ω–∞"
            else:
                base_answer += "\n\nüíô –° —É–≤–∞–∂–µ–Ω–∏–µ–º, –û–ª–µ–Ω–∞"

            return {
                "answer": base_answer,
                "confidence": confidence,
                "source": "enhanced_mock",
                "context_used": bool(context),
                "persona_name": "–û–ª–µ–Ω–∞",
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ Enhanced Mock: {e}")
            raise

    async def _get_user_context(self, user_id: int, current_message: str) -> Dict:
        """–ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏"""
        try:
            # –ë–∞–∑–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
            context = {
                "user_id": user_id,
                "last_message": current_message,
                "is_returning_user": False,
                "total_messages": 0,
                "favorite_category": None,
            }

            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            stats = unified_db.get_user_stats_summary(user_id)
            if stats:
                context.update(
                    {
                        "is_returning_user": stats.get("total_messages", 0) > 1,
                        "total_messages": stats.get("total_messages", 0),
                        "favorite_category": stats.get("top_category"),
                    }
                )

            return context

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {e}")
            return {"user_id": user_id, "last_message": current_message}

    def _calculate_enhanced_confidence(self, answer: str, context: str, query: str) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞"""
        confidence = 0.5  # –ë–∞–∑–æ–≤–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å

        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –µ—Å–ª–∏ –µ—Å—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç
        if context:
            confidence += 0.3

        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        if any(word in answer.lower() for word in ["–≥—Ä–Ω", "–¥–µ–Ω—å", "—á–∞—Å", "—Ä–∞–∑–º–µ—Ä", "—Ä–æ–∑–º—ñ—Ä"]):
            confidence += 0.2

        # –£–º–µ–Ω—å—à–∞–µ–º –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º –æ–±—â–∏–π
        if any(phrase in answer.lower() for phrase in ["–∑–≤'—è–∂—ñ—Ç—å—Å—è", "—Å–≤—è–∂–∏—Ç–µ—Å—å", "—É—Ç–æ—á–Ω–∏—Ç–µ"]):
            confidence -= 0.1

        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∑–∞ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
        if any(word in answer.lower() for word in ["–æ–ª–µ–Ω–∞", "–¥–æ—Å–≤—ñ–¥", "–æ–ø—ã—Ç", "–ø–∞–º'—è—Ç–∞—é", "–ø–æ–º–Ω—é"]):
            confidence += 0.1

        return max(0.0, min(1.0, confidence))

    async def _fallback_response(self, user_query: str, user_id: int, language: str) -> Dict:
        """Fallback –æ—Ç–≤–µ—Ç –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ AI"""
        if language == "ukr":
            answer = "–í–∏–±–∞—á—Ç–µ, –∑–∞—Ä–∞–∑ —è –Ω–µ –º–æ–∂—É –¥–∞—Ç–∏ –ø–æ–≤–Ω—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å. –ó–≤'—è–∂—ñ—Ç—å—Å—è –∑ –Ω–∞—à–∏–º –º–µ–Ω–µ–¥–∂–µ—Ä–æ–º –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ—ó –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü—ñ—ó!"
        else:
            answer = "–ò–∑–≤–∏–Ω–∏—Ç–µ, —Å–µ–π—á–∞—Å –Ω–µ –º–æ–≥—É –¥–∞—Ç—å –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç. –°–≤—è–∂–∏—Ç–µ—Å—å —Å –Ω–∞—à–∏–º –º–µ–Ω–µ–¥–∂–µ—Ä–æ–º –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏!"

        return {
            "answer": answer,
            "confidence": 0.1,
            "source": "fallback",
            "enhanced": True,
            "response_time_ms": 100,
        }

    def get_service_info(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–µ—Ä–≤–∏—Å–µ"""
        return {
            "service_type": "Enhanced AI Service",
            "persona_enabled": True,
            "persona_name": "–û–ª–µ–Ω–∞",
            "ai_enabled": self.enabled,
            "real_ai": self.use_real_ai,
            "knowledge_ready": self.knowledge_ready,
            "model": self.config.AI_MODEL if self.use_real_ai else "Mock",
        }


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ AI —Å–µ—Ä–≤–∏—Å–∞
enhanced_ai_service = EnhancedAIService()
