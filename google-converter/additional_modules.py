# ============================================================================
# –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –≠–ö–°–ü–û–†–¢–ï–†–´ / ADDITIONAL EXPORTERS
# ============================================================================

class TXTExporter(BaseExporter):
    """–≠–∫—Å–ø–æ—Ä—Ç–µ—Ä –≤ —á–∏—Ç–∞–µ–º—ã–π TXT —Ñ–æ—Ä–º–∞—Ç"""
    
    def __init__(self, output_dir: str):
        super().__init__(output_dir, 'txt')
    
    def get_extension(self) -> str:
        return 'txt'
    
    def export_data(self, data: pd.DataFrame, filepath: str, **kwargs) -> None:
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(f"üìã –î–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã\n")
            f.write("=" * 60 + "\n\n")
            
            for index, row in data.iterrows():
                f.write(f"üî∏ –ó–∞–ø–∏—Å—å #{index + 1}\n")
                f.write("-" * 30 + "\n")
                
                for column in data.columns:
                    value = row[column]
                    if pd.notna(value):
                        f.write(f"üìå {column}: {value}\n")
                
                f.write("\n" + "=" * 60 + "\n\n")


class HTMLExporter(BaseExporter):
    """–≠–∫—Å–ø–æ—Ä—Ç–µ—Ä –≤ HTML —Å –∫—Ä–∞—Å–∏–≤—ã–º —Å—Ç–∏–ª–µ–º"""
    
    def __init__(self, output_dir: str):
        super().__init__(output_dir, 'html')
    
    def get_extension(self) -> str:
        return 'html'
    
    def export_data(self, data: pd.DataFrame, filepath: str, **kwargs) -> None:
        title = kwargs.get('title', 'Google Sheets Data')
        
        html_content = f"""
<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }}
        .container {{
            background: white;
            border-radius: 10px;
            padding: 30px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
        h1 {{
            color: #333;
            border-bottom: 3px solid #007bff;
            padding-bottom: 10px;
        }}
        table {{
            width: 100%;
            border-collapse: collapse;
            margin-top: 20px;
        }}
        th, td {{
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
            vertical-align: top;
        }}
        th {{
            background-color: #007bff;
            color: white;
            font-weight: bold;
        }}
        tr:nth-child(even) {{
            background-color: #f9f9f9;
        }}
        tr:hover {{
            background-color: #f5f5f5;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>üìã {title}</h1>
        <div>–°–æ–∑–¥–∞–Ω–æ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</div>
        <table>
"""
        
        if not data.empty:
            # –ó–∞–≥–æ–ª–æ–≤–∫–∏
            html_content += "            <thead><tr>\n"
            for column in data.columns:
                html_content += f"                <th>{column}</th>\n"
            html_content += "            </tr></thead>\n            <tbody>\n"
            
            # –î–∞–Ω–Ω—ã–µ
            for _, row in data.iterrows():
                html_content += "                <tr>\n"
                for column in data.columns:
                    value = row[column] if pd.notna(row[column]) else ""
                    value = str(value).replace('\n', '<br>')
                    html_content += f"                    <td>{value}</td>\n"
                html_content += "                </tr>\n"
            
            html_content += "            </tbody>\n"
        
        html_content += """        </table>
    </div>
</body>
</html>"""
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(html_content)


class ParquetExporter(BaseExporter):
    """–≠–∫—Å–ø–æ—Ä—Ç–µ—Ä –≤ Parquet —Ñ–æ—Ä–º–∞—Ç"""
    
    def __init__(self, output_dir: str):
        super().__init__(output_dir, 'parquet')
    
    def get_extension(self) -> str:
        return 'parquet'
    
    def export_data(self, data: pd.DataFrame, filepath: str, **kwargs) -> None:
        try:
            import pyarrow.parquet as pq
            compression = kwargs.get('compression', 'snappy')
            data.to_parquet(filepath, compression=compression)
        except ImportError:
            raise ImportError("pyarrow required for Parquet export")


# ============================================================================
# –†–ê–°–®–ò–†–ï–ù–ù–´–ï –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò / ADVANCED PROCESSORS
# ============================================================================

class HeaderValidator:
    """–í–∞–ª–∏–¥–∞—Ç–æ—Ä –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ —Ç–∞–±–ª–∏—Ü—ã"""
    
    def __init__(self, expected_headers: List[str], strict: bool = True):
        self.expected_headers = expected_headers
        self.strict = strict
    
    def process(self, data: pd.DataFrame) -> pd.DataFrame:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏"""
        if self.strict:
            actual_headers = data.columns.tolist()
            
            if len(actual_headers) != len(self.expected_headers):
                raise ValueError(
                    f"Header count mismatch: {len(actual_headers)} != {len(self.expected_headers)}"
                )
            
            for i, (actual, expected) in enumerate(zip(actual_headers, self.expected_headers)):
                if actual.strip().lower() != expected.lower():
                    raise ValueError(
                        f"Header mismatch at position {i}: '{actual}' != '{expected}'"
                    )
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
        data.columns = [col.strip().lower() for col in data.columns]
        return data


class DataCleaner:
    """–û—á–∏—Å—Ç–∏—Ç–µ–ª—å –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self, 
                 remove_empty_rows: bool = True,
                 remove_empty_cols: bool = False,
                 fill_na_value: Any = ''):
        self.remove_empty_rows = remove_empty_rows
        self.remove_empty_cols = remove_empty_cols
        self.fill_na_value = fill_na_value
    
    def process(self, data: pd.DataFrame) -> pd.DataFrame:
        """–û—á–∏—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ"""
        df = data.copy()
        
        if self.remove_empty_rows:
            df = df.dropna(how='all')
        
        if self.remove_empty_cols:
            df = df.dropna(axis=1, how='all')
        
        if self.fill_na_value is not None:
            df = df.fillna(self.fill_na_value)
        
        return df


class DataTransformer:
    """–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏"""
    
    def __init__(self, transformations: Dict[str, callable]):
        self.transformations = transformations
    
    def process(self, data: pd.DataFrame) -> pd.DataFrame:
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∫ –∫–æ–ª–æ–Ω–∫–∞–º"""
        df = data.copy()
        
        for column, transform_func in self.transformations.items():
            if column in df.columns:
                df[column] = df[column].apply(transform_func)
        
        return df


# ============================================================================
# –£–õ–£–ß–®–ï–ù–ù–ê–Ø –°–ò–°–¢–ï–ú–ê –ö–ï–®–ò–†–û–í–ê–ù–ò–Ø / ADVANCED CACHING
# ============================================================================

class MemoryCache:
    """–ö–µ—à –≤ –ø–∞–º—è—Ç–∏ (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)"""
    
    def __init__(self):
        self.cache_data = {}
    
    def get(self, key: str) -> Optional[Any]:
        return self.cache_data.get(key)
    
    def set(self, key: str, value: Any) -> None:
        self.cache_data[key] = value
    
    def is_changed(self, key: str, data: str) -> bool:
        current_hash = hashlib.md5(data.encode('utf-8')).hexdigest()
        cached_entry = self.get(key)
        
        if cached_entry and cached_entry.get('hash') == current_hash:
            return False
        
        self.set(key, {
            'hash': current_hash,
            'last_updated': datetime.now().isoformat()
        })
        return True


class RedisCache:
    """–ö–µ—à –Ω–∞ –±–∞–∑–µ Redis (–¥–ª—è production)"""
    
    def __init__(self, redis_client, ttl: int = 3600):
        self.redis = redis_client
        self.ttl = ttl
    
    def get(self, key: str) -> Optional[Any]:
        try:
            data = self.redis.get(key)
            return json.loads(data) if data else None
        except Exception:
            return None
    
    def set(self, key: str, value: Any) -> None:
        try:
            self.redis.setex(key, self.ttl, json.dumps(value, default=str))
        except Exception:
            pass
    
    def is_changed(self, key: str, data: str) -> bool:
        current_hash = hashlib.md5(data.encode('utf-8')).hexdigest()
        cached_entry = self.get(key)
        
        if cached_entry and cached_entry.get('hash') == current_hash:
            return False
        
        self.set(key, {
            'hash': current_hash,
            'last_updated': datetime.now().isoformat()
        })
        return True


# ============================================================================
# –§–ê–ë–†–ò–ö–ò –î–õ–Ø –£–î–û–ë–ù–û–ì–û –°–û–ó–î–ê–ù–ò–Ø / FACTORIES
# ============================================================================

class ConverterFactory:
    """–§–∞–±—Ä–∏–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è–º–∏"""
    
    @staticmethod
    def create_basic_converter(output_dir: str = "output", 
                             api_key: Optional[str] = None) -> ModularSheetsConverter:
        """–°–æ–∑–¥–∞–µ—Ç –±–∞–∑–æ–≤—ã–π –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä"""
        config = Config(api_key=api_key, output_dir=output_dir)
        cache = FileCache(config.cache_file)
        
        converter = ModularSheetsConverter(config=config, cache=cache)
        
        # –ë–∞–∑–æ–≤—ã–µ —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä—ã
        converter.register_exporter('csv', CSVExporter(output_dir))
        converter.register_exporter('json', JSONExporter(output_dir))
        converter.register_exporter('txt', TXTExporter(output_dir))
        
        # –ë–∞–∑–æ–≤—ã–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
        converter.add_processor(DataCleaner())
        converter.add_processor(TextFieldProcessor(auto_detect=True))
        
        return converter
    
    @staticmethod
    def create_full_converter(output_dir: str = "output",
                            api_key: Optional[str] = None,
                            enable_redis: bool = False) -> ModularSheetsConverter:
        """–°–æ–∑–¥–∞–µ—Ç –ø–æ–ª–Ω–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä"""
        config = Config(api_key=api_key, output_dir=output_dir, batch_size=100)
        
        # –í—ã–±–∏—Ä–∞–µ–º —Ç–∏–ø –∫–µ—à–∞
        if enable_redis:
            try:
                import redis
                redis_client = redis.Redis(host='localhost', port=6379, db=0)
                cache = RedisCache(redis_client)
            except ImportError:
                print("‚ö†Ô∏è Redis –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∞–π–ª–æ–≤—ã–π –∫–µ—à")
                cache = FileCache(config.cache_file)
        else:
            cache = FileCache(config.cache_file)
        
        converter = ModularSheetsConverter(config=config, cache=cache)
        
        # –í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä—ã
        converter.register_exporter('csv', CSVExporter(output_dir))
        converter.register_exporter('json', JSONExporter(output_dir))
        converter.register_exporter('txt', TXTExporter(output_dir))
        converter.register_exporter('html', HTMLExporter(output_dir))
        converter.register_exporter('yaml', YAMLExporter(output_dir))
        
        if XLSX_AVAILABLE:
            converter.register_exporter('xlsx', ExcelExporter(output_dir))
        
        try:
            converter.register_exporter('parquet', ParquetExporter(output_dir))
        except ImportError:
            pass
        
        # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
        converter.add_processor(DataCleaner(remove_empty_rows=True))
        converter.add_processor(TextFieldProcessor(auto_detect=True))
        
        return converter


# ============================================================================
# –¢–ï–°–¢–´ / TESTS
# ============================================================================

def test_basic_functionality():
    """–ë–∞–∑–æ–≤—ã–µ —Ç–µ—Å—Ç—ã —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏"""
    print("üß™ –ó–∞–ø—É—Å–∫ –±–∞–∑–æ–≤—ã—Ö —Ç–µ—Å—Ç–æ–≤...")
    
    # –¢–µ—Å—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config = Config(api_key="test_key", output_dir="test_output")
    assert config.api_key == "test_key"
    assert config.output_dir == "test_output"
    print("‚úÖ –¢–µ—Å—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø—Ä–æ–π–¥–µ–Ω")
    
    # –¢–µ—Å—Ç –∫–µ—à–∞
    cache = MemoryCache()
    cache.set("test_key", {"value": "test"})
    assert cache.get("test_key")["value"] == "test"
    print("‚úÖ –¢–µ—Å—Ç –∫–µ—à–∞ –ø—Ä–æ–π–¥–µ–Ω")
    
    # –¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö
    df = pd.DataFrame({
        'col1': ['value1', 'value2\nwith\nnewlines'],
        'col2': [1, 2]
    })
    
    processor = TextFieldProcessor(auto_detect=True)
    processed_df = processor.process(df)
    assert processed_df is not None
    print("‚úÖ –¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ —Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ–π–¥–µ–Ω")
    
    # –¢–µ—Å—Ç —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä–æ–≤
    import tempfile
    with tempfile.TemporaryDirectory() as temp_dir:
        csv_exporter = CSVExporter(temp_dir)
        filepath = csv_exporter.export(df, "test")
        assert os.path.exists(filepath)
        print("‚úÖ –¢–µ—Å—Ç CSV —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä–∞ –ø—Ä–æ–π–¥–µ–Ω")
        
        json_exporter = JSONExporter(temp_dir)
        filepath = json_exporter.export(df, "test")
        assert os.path.exists(filepath)
        print("‚úÖ –¢–µ—Å—Ç JSON —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä–∞ –ø—Ä–æ–π–¥–µ–Ω")
    
    print("üéâ –í—Å–µ –±–∞–∑–æ–≤—ã–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã!")


def test_integration():
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç —Å —Ä–µ–∞–ª—å–Ω–æ–π —Ç–∞–±–ª–∏—Ü–µ–π"""
    print("üß™ –ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞...")
    
    url = "https://docs.google.com/spreadsheets/d/1RagVK40gWitjfQE-_wBD8HnSaeDGGMZJ2uWfICLRqFQ/edit"
    
    try:
        import tempfile
        with tempfile.TemporaryDirectory() as temp_dir:
            # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            converter = ConverterFactory.create_basic_converter(output_dir=temp_dir)
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ ID
            client = GoogleSheetsClient(Config())
            sheet_id = client.extract_sheet_id(url)
            assert len(sheet_id) > 10
            print("‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ID –ø—Ä–æ–π–¥–µ–Ω–æ")
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            sheets_info = client.get_sheets_metadata(sheet_id)
            assert len(sheets_info) > 0
            print("‚úÖ –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–π–¥–µ–Ω–æ")
            
            print("üéâ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω!")
            
    except Exception as e:
        print(f"‚ùå –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç –Ω–µ—É–¥–∞—á–µ–Ω: {e}")


def test_performance():
    """–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    print("üß™ –¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏...")
    
    # –°–æ–∑–¥–∞–µ–º –±–æ–ª—å—à–æ–π DataFrame –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    large_df = pd.DataFrame({
        f'col_{i}': [f'value_{j}_{i}' for j in range(1000)]
        for i in range(10)
    })
    
    import time
    start_time = time.time()
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
    processor = TextFieldProcessor(auto_detect=True)
    processed_df = processor.process(large_df)
    
    processing_time = time.time() - start_time
    print(f"‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ 10,000 —è—á–µ–µ–∫: {processing_time:.3f} —Å–µ–∫")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —ç–∫—Å–ø–æ—Ä—Ç
    import tempfile
    with tempfile.TemporaryDirectory() as temp_dir:
        start_time = time.time()
        
        csv_exporter = CSVExporter(temp_dir)
        csv_exporter.export(processed_df, "performance_test")
        
        export_time = time.time() - start_time
        print(f"‚è±Ô∏è –í—Ä–µ–º—è CSV —ç–∫—Å–ø–æ—Ä—Ç–∞: {export_time:.3f} —Å–µ–∫")
    
    print("üéâ –¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–≤–µ—Ä—à–µ–Ω!")


# ============================================================================
# –†–ê–°–®–ò–†–ï–ù–ù–´–ï –ü–†–ò–ú–ï–†–´ –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø / ADVANCED USAGE EXAMPLES
# ============================================================================

def example_custom_processor():
    """–ü—Ä–∏–º–µ—Ä —Å–æ–∑–¥–∞–Ω–∏—è –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞"""
    
    class EmailMaskProcessor:
        """–ú–∞—Å–∫–∏—Ä—É–µ—Ç email –∞–¥—Ä–µ—Å–∞ –≤ –¥–∞–Ω–Ω—ã—Ö"""
        
        def process(self, data: pd.DataFrame) -> pd.DataFrame:
            df = data.copy()
            
            for column in df.columns:
                if 'email' in column.lower():
                    df[column] = df[column].astype(str).str.replace(
                        r'(\w+)@(\w+\.\w+)',
                        r'\1@***.\2',
                        regex=True
                    )
            
            return df
    
    # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
    converter = ConverterFactory.create_basic_converter()
    converter.add_processor(EmailMaskProcessor())
    
    print("‚úÖ –ö–∞—Å—Ç–æ–º–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–∑–¥–∞–Ω")


def example_custom_exporter():
    """–ü—Ä–∏–º–µ—Ä —Å–æ–∑–¥–∞–Ω–∏—è –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä–∞"""
    
    class SQLExporter(BaseExporter):
        """–≠–∫—Å–ø–æ—Ä—Ç–µ—Ä –≤ SQL INSERT statements"""
        
        def __init__(self, output_dir: str, table_name: str = "data"):
            super().__init__(output_dir, 'sql')
            self.table_name = table_name
        
        def get_extension(self) -> str:
            return 'sql'
        
        def export_data(self, data: pd.DataFrame, filepath: str, **kwargs) -> None:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(f"-- SQL export for {self.table_name}\n")
                f.write(f"CREATE TABLE IF NOT EXISTS {self.table_name} (\n")
                
                # –°–æ–∑–¥–∞–µ–º —Å—Ö–µ–º—É
                columns = []
                for col in data.columns:
                    columns.append(f"    {col} TEXT")
                f.write(",\n".join(columns))
                f.write("\n);\n\n")
                
                # –°–æ–∑–¥–∞–µ–º INSERT statements
                for _, row in data.iterrows():
                    values = []
                    for value in row:
                        if pd.isna(value):
                            values.append("NULL")
                        else:
                            escaped_value = str(value).replace("'", "''")
                            values.append(f"'{escaped_value}'")
                    
                    f.write(f"INSERT INTO {self.table_name} VALUES ({', '.join(values)});\n")
    
    # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
    converter = ConverterFactory.create_basic_converter()
    converter.register_exporter('sql', SQLExporter(converter.config.output_dir, 'my_table'))
    
    print("‚úÖ –ö–∞—Å—Ç–æ–º–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä —Å–æ–∑–¥–∞–Ω")


# ============================================================================
# –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –î–õ–Ø –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–ò / MAIN DEMO FUNCTION
# ============================================================================

def demo_modular_converter():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –º–æ–¥—É–ª—å–Ω–æ–≥–æ –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞"""
    
    print("üöÄ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –º–æ–¥—É–ª—å–Ω–æ–≥–æ Google Sheets –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞")
    print("=" * 60)
    
    url = "https://docs.google.com/spreadsheets/d/1RagVK40gWitjfQE-_wBD8HnSaeDGGMZJ2uWfICLRqFQ/edit"
    
    # 1. –ü—Ä–æ—Å—Ç–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
    print("\n1Ô∏è‚É£ –ü—Ä–æ—Å—Ç–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è:")
    result = quick_convert(url, formats=['csv', 'json'], output_dir="demo_output")
    print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ª–∏—Å—Ç–æ–≤: {result['summary']['processed_sheets']}")
    
    # 2. –ü–æ–ª–Ω–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
    print("\n2Ô∏è‚É£ –ü–æ–ª–Ω–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è:")
    converter = ConverterFactory.create_full_converter(output_dir="demo_full")
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
    converter.add_processor(DataTransformer({
        'sort_order': lambda x: int(x) if pd.notna(x) and str(x).isdigit() else 0
    }))
    
    formats = ['csv', 'json', 'txt', 'html', 'yaml']
    if XLSX_AVAILABLE:
        formats.append('xlsx')
    
    result = converter.convert_spreadsheet(url, formats)
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {result['summary']['files_created']}")
    
    # 3. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    print("\n3Ô∏è‚É£ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤:")
    test_basic_functionality()
    test_integration()
    test_performance()
    
    print("\nüéâ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")


if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    demo_modular_converter()
