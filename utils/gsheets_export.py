#!/usr/bin/env python3
"""
Universal Google Sheets to Multiple Formats Converter
–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä Google –¢–∞–±–ª–∏—Ü –≤ —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
"""

import re

import json
import os
import pandas as pd
import requests
import sys
import yaml
from datetime import datetime
from typing import Any, Dict, List, Tuple

from config import GOOGLE_SHEETS_API_KEY

# –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã
try:
    import openpyxl

    XLSX_AVAILABLE = True
except ImportError:
    XLSX_AVAILABLE = False

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
URL_TEST = "https://docs.google.com/spreadsheets/d/1RagVK40gWitjfQE-_wBD8HnSaeDGGMZJ2uWfICLRqFQ/edit?usp=sharing"
FILE_PATH = "../converted-data"


class UniversalSheetsConverter:
    def __init__(self, formats=["csv", "json", "txt"], transliterate=True):
        self.enabled_formats = set(formats)
        self.transliterate_names = transliterate
        self.output_dir = FILE_PATH
        self.api_key = GOOGLE_SHEETS_API_KEY

        # –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã (—É–±—Ä–∞–ª–∏ PDF)
        self.available_formats = {
            "csv": {"name": "CSV —Ñ–∞–π–ª—ã (–¥–ª—è –ø–∞—Ä—Å–µ—Ä–æ–≤)", "ext": "csv", "folder": "csv"},
            "json": {
                "name": "JSON —Ñ–∞–π–ª—ã (—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)",
                "ext": "json",
                "folder": "json",
            },
            "txt": {"name": "TXT —Ñ–∞–π–ª—ã (–¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞)", "ext": "txt", "folder": "txt"},
            "xlsx": {
                "name": "Excel —Ñ–∞–π–ª—ã (—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)",
                "ext": "xlsx",
                "folder": "excel",
            },
            "md": {
                "name": "Markdown –¥–æ–∫—É–º–µ–Ω—Ç—ã (–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è)",
                "ext": "md",
                "folder": "markdown",
            },
            "html": {
                "name": "HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–±—Ä–∞—É–∑–µ—Ä)",
                "ext": "html",
                "folder": "html",
            },
            "yaml": {
                "name": "YAML –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (DevOps)",
                "ext": "yml",
                "folder": "yaml",
            },
        }

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –æ—Ç—á–µ—Ç–∞
        self.stats = {
            "start_time": datetime.now(),
            "end_time": None,
            "total_sheets": 0,
            "processed_sheets": 0,
            "skipped_sheets": 0,
            "formats_used": list(self.enabled_formats),
            "transliteration_enabled": self.transliterate_names,
            "sheets_details": [],
            "files_created": [],
        }

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Ñ–æ—Ä–º–∞—Ç–æ–≤
        self._check_format_availability()

    def _check_format_availability(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Ñ–æ—Ä–º–∞—Ç–æ–≤ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–µ—Ç –æ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ö"""
        if "xlsx" in self.enabled_formats and not XLSX_AVAILABLE:
            print(
                "‚ö†Ô∏è –î–ª—è Excel —Ñ–æ—Ä–º–∞—Ç–∞ –Ω—É–∂–Ω–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ openpyxl: pip install openpyxl"
            )
            self.enabled_formats.discard("xlsx")

    def create_output_directories(self):
        """–°–æ–∑–¥–∞–µ—Ç –≤—ã—Ö–æ–¥–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –≤—Å–µ—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤"""
        for format_key in self.enabled_formats:
            if format_key in self.available_formats:
                folder_path = os.path.join(
                    self.output_dir, self.available_formats[format_key]["folder"]
                )
                os.makedirs(folder_path, exist_ok=True)

        print(f"üìÅ –†–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {self.output_dir}/")
        print(f"üìã –ê–∫—Ç–∏–≤–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: {', '.join(self.enabled_formats)}")

    def extract_sheet_id(self, url: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç ID —Ç–∞–±–ª–∏—Ü—ã –∏–∑ URL"""
        pattern = r"/spreadsheets/d/([a-zA-Z0-9-_]+)"
        match = re.search(pattern, url)
        if not match:
            raise ValueError("–ù–µ–≤–µ—Ä–Ω–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ Google –¢–∞–±–ª–∏—Ü—É")
        return match.group(1)

    def get_all_sheets_info(self, sheet_id: str) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö —á–µ—Ä–µ–∑ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π Google Sheets API"""
        print("üîç –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ª–∏—Å—Ç–∞—Ö —á–µ—Ä–µ–∑ Google Sheets API...")

        try:
            api_url = f"https://sheets.googleapis.com/v4/spreadsheets/{sheet_id}"
            params = {}
            if self.api_key:
                params["key"] = self.api_key
                print(f"üîë –ò—Å–ø–æ–ª—å–∑—É–µ–º API key: {self.api_key[:20]}...")

            headers = {"User-Agent": "UniversalSheetsConverter/1.0"}
            response = requests.get(api_url, params=params, headers=headers, timeout=15)

            if response.status_code == 200:
                data = response.json()
                sheets_info = []

                sheets = data.get("sheets", [])
                for sheet in sheets:
                    sheet_properties = sheet.get("properties", {})
                    sheet_id_num = sheet_properties.get("sheetId", 0)
                    sheet_title = sheet_properties.get("title", f"Sheet{sheet_id_num}")

                    sheets_info.append({"gid": str(sheet_id_num), "name": sheet_title})

                if sheets_info:
                    print(f"üìÑ –ù–∞–π–¥–µ–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü —á–µ—Ä–µ–∑ API: {len(sheets_info)}")
                    for i, sheet in enumerate(sheets_info, 1):
                        print(f"   {i}. '{sheet['name']}' (gid: {sheet['gid']})")
                    return sheets_info
                else:
                    print("‚ö†Ô∏è API –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –ª–∏—Å—Ç–æ–≤")
                    return [{"gid": "0", "name": "Sheet1"}]

            elif response.status_code == 403:
                print(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ (HTTP 403)")
                print(
                    "üí° –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å API –∫–ª—é—á–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–æ—Å—Ç—É–ø–∞ –∫ —Ç–∞–±–ª–∏—Ü–µ"
                )
                return [{"gid": "0", "name": "Sheet1"}]

            elif response.status_code == 404:
                print(f"‚ùå –¢–∞–±–ª–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ (HTTP 404)")
                print("üí° –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å ID —Ç–∞–±–ª–∏—Ü—ã")
                return [{"gid": "0", "name": "Sheet1"}]

            else:
                print(f"‚ùå API –≤–µ—Ä–Ω—É–ª –æ—à–∏–±–∫—É HTTP {response.status_code}")
                return [{"gid": "0", "name": "Sheet1"}]

        except requests.RequestException as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ API: {e}")
            return [{"gid": "0", "name": "Sheet1"}]

        except Exception as e:
            print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å API: {e}")
            return [{"gid": "0", "name": "Sheet1"}]

    def get_csv_url(self, sheet_id: str, gid: str) -> str:
        """–§–æ—Ä–º–∏—Ä—É–µ—Ç URL –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤ CSV"""
        return f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gid}"

    def load_sheet_data(
        self, sheet_id: str, gid: str, sheet_name: str
    ) -> Tuple[pd.DataFrame, bool]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            csv_url = self.get_csv_url(sheet_id, gid)
            print(f"üì• –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É: {sheet_name}")

            df = pd.read_csv(csv_url)

            # –£–¥–∞–ª—è–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            df = df.dropna(how="all")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
            print(
                f"üìä [{sheet_name}] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫"
            )

            return df, True

        except Exception as e:
            print(f"‚ùå [{sheet_name}] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            return pd.DataFrame(), False

    def detect_text_columns(self, df: pd.DataFrame) -> List[str]:
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ —Å—Ç—Ä–æ–∫"""
        text_columns = []

        for column in df.columns:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –ø–µ—Ä–µ–Ω–æ—Å–æ–≤
            sample_data = df[column].dropna().astype(str).head(10)
            has_newlines = any("\n" in str(value) for value in sample_data)

            # –ï—Å–ª–∏ –µ—Å—Ç—å –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –∏–ª–∏ –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç, —Å—á–∏—Ç–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–π –∫–æ–ª–æ–Ω–∫–æ–π
            avg_length = sample_data.str.len().mean() if len(sample_data) > 0 else 0

            if has_newlines or avg_length > 50:  # –ü–æ—Ä–æ–≥ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞
                text_columns.append(column)

        return text_columns

    def process_text_fields(self, df: pd.DataFrame) -> pd.DataFrame:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è - –æ—á–∏—â–∞–µ—Ç –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã, –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–∞—Ç–∏–≤–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã"""
        df_processed = df.copy()
        text_columns = self.detect_text_columns(df)

        if text_columns:
            print(f"üî§ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {', '.join(text_columns)}")

            for column in text_columns:
                if column in df_processed.columns:
                    # –£–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –ª–∏—à–Ω–∏–µ \r —Å–∏–º–≤–æ–ª—ã, –æ—Å—Ç–∞–≤–ª—è–µ–º –Ω–∞—Ç–∏–≤–Ω—ã–µ \n
                    df_processed[column] = (
                        df_processed[column]
                        .astype(str)
                        .str.replace("\r", "", regex=False)
                    )

        return df_processed

    def transliterate_russian(self, text: str) -> str:
        """–¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä—É–µ—Ç —Ä—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç –≤ –ª–∞—Ç–∏–Ω–∏—Ü—É"""
        if not self.transliterate_names:
            return text

        translit_dict = {
            "–∞": "a",
            "–±": "b",
            "–≤": "v",
            "–≥": "g",
            "–¥": "d",
            "–µ": "e",
            "—ë": "yo",
            "–∂": "zh",
            "–∑": "z",
            "–∏": "i",
            "–π": "y",
            "–∫": "k",
            "–ª": "l",
            "–º": "m",
            "–Ω": "n",
            "–æ": "o",
            "–ø": "p",
            "—Ä": "r",
            "—Å": "s",
            "—Ç": "t",
            "—É": "u",
            "—Ñ": "f",
            "—Ö": "h",
            "—Ü": "ts",
            "—á": "ch",
            "—à": "sh",
            "—â": "sch",
            "—ä": "",
            "—ã": "y",
            "—å": "",
            "—ç": "e",
            "—é": "yu",
            "—è": "ya",
            "–ê": "A",
            "–ë": "B",
            "–í": "V",
            "–ì": "G",
            "–î": "D",
            "–ï": "E",
            "–Å": "Yo",
            "–ñ": "Zh",
            "–ó": "Z",
            "–ò": "I",
            "–ô": "Y",
            "–ö": "K",
            "–õ": "L",
            "–ú": "M",
            "–ù": "N",
            "–û": "O",
            "–ü": "P",
            "–†": "R",
            "–°": "S",
            "–¢": "T",
            "–£": "U",
            "–§": "F",
            "–•": "H",
            "–¶": "Ts",
            "–ß": "Ch",
            "–®": "Sh",
            "–©": "Sch",
            "–™": "",
            "–´": "Y",
            "–¨": "",
            "–≠": "E",
            "–Æ": "Yu",
            "–Ø": "Ya",
        }

        result = ""
        for char in text:
            result += translit_dict.get(char, char)

        return result

    def clean_filename(self, sheet_name: str) -> str:
        """–û—á–∏—â–∞–µ—Ç –∏–º—è –ª–∏—Å—Ç–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞"""
        # –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä—É–µ–º –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
        clean_name = self.transliterate_russian(sheet_name)

        # –ó–∞–º–µ–Ω—è–µ–º –Ω–µ–±–µ–∑–æ–ø–∞—Å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –Ω–∞ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è
        clean_name = re.sub(r"[^a-zA-Z0-9\-]", "_", clean_name)
        clean_name = re.sub(r"_+", "_", clean_name)
        clean_name = clean_name.strip("_").lower()

        return clean_name if clean_name else "sheet"

    def save_csv(self, df: pd.DataFrame, sheet_name: str, page_num: int):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç DataFrame –≤ CSV"""
        if "csv" not in self.enabled_formats:
            return

        clean_name = self.clean_filename(sheet_name)
        filename = f"{clean_name}_page_{page_num:02d}.csv"
        filepath = os.path.join(self.output_dir, "csv", filename)

        df.to_csv(filepath, index=False, sep=";", encoding="utf-8", quoting=1)
        print(f"üíæ CSV —Å–æ—Ö—Ä–∞–Ω–µ–Ω: csv/{filename}")

        # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.stats["files_created"].append(
            {
                "format": "csv",
                "filename": f"csv/{filename}",
                "size_bytes": os.path.getsize(filepath),
            }
        )

    def save_json(self, df: pd.DataFrame, sheet_name: str, page_num: int):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç DataFrame –≤ JSON"""
        if "json" not in self.enabled_formats:
            return

        clean_name = self.clean_filename(sheet_name)
        filename = f"{clean_name}_page_{page_num:02d}.json"
        filepath = os.path.join(self.output_dir, "json", filename)

        data = df.to_dict("records")
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=4)

        print(f"üíæ JSON —Å–æ—Ö—Ä–∞–Ω–µ–Ω: json/{filename}")

        # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.stats["files_created"].append(
            {
                "format": "json",
                "filename": f"json/{filename}",
                "size_bytes": os.path.getsize(filepath),
            }
        )

    def save_txt(
        self,
        df: pd.DataFrame,
        df_original: pd.DataFrame,
        sheet_name: str,
        page_num: int,
    ):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç DataFrame –≤ TXT –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞"""
        if "txt" not in self.enabled_formats:
            return

        clean_name = self.clean_filename(sheet_name)
        filename = f"{clean_name}_page_{page_num:02d}.txt"
        filepath = os.path.join(self.output_dir, "txt", filename)

        with open(filepath, "w", encoding="utf-8") as f:
            f.write(f"üìã {sheet_name} - –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}\n")
            f.write("=" * 60 + "\n\n")

            for index, row in df_original.iterrows():
                f.write(f"üî∏ –ó–∞–ø–∏—Å—å #{index + 1}\n")
                f.write("-" * 30 + "\n")

                for column in df_original.columns:
                    value = row[column]
                    if pd.notna(value):
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Ç–∏–≤–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –∫–∞–∫ –µ—Å—Ç—å
                        display_value = str(value)
                        f.write(f"üìå {column}: {display_value}\n")

                f.write("\n" + "=" * 60 + "\n\n")

        print(f"üìÑ TXT —Å–æ—Ö—Ä–∞–Ω–µ–Ω: txt/{filename}")

        # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.stats["files_created"].append(
            {
                "format": "txt",
                "filename": f"txt/{filename}",
                "size_bytes": os.path.getsize(filepath),
            }
        )

    def save_xlsx(self, df: pd.DataFrame, sheet_name: str, page_num: int):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç DataFrame –≤ Excel"""
        if "xlsx" not in self.enabled_formats or not XLSX_AVAILABLE:
            return

        clean_name = self.clean_filename(sheet_name)
        filename = f"{clean_name}_page_{page_num:02d}.xlsx"
        filepath = os.path.join(self.output_dir, "excel", filename)

        # Excel –Ω–∞—Ç–∏–≤–Ω–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∫–∞–∫ –µ—Å—Ç—å
        df.to_excel(filepath, index=False, engine="openpyxl")
        print(f"üìä Excel —Å–æ—Ö—Ä–∞–Ω–µ–Ω: excel/{filename}")

        # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.stats["files_created"].append(
            {
                "format": "xlsx",
                "filename": f"excel/{filename}",
                "size_bytes": os.path.getsize(filepath),
            }
        )

    def save_markdown(
        self,
        df: pd.DataFrame,
        df_original: pd.DataFrame,
        sheet_name: str,
        page_num: int,
    ):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç DataFrame –≤ Markdown"""
        if "md" not in self.enabled_formats:
            return

        clean_name = self.clean_filename(sheet_name)
        filename = f"{clean_name}_page_{page_num:02d}.md"
        filepath = os.path.join(self.output_dir, "markdown", filename)

        with open(filepath, "w", encoding="utf-8") as f:
            f.write(f"# üìã {sheet_name} - –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}\n\n")
            f.write(f"*–°–æ–∑–¥–∞–Ω–æ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n\n")

            # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
            if not df_original.empty:
                # –ó–∞–≥–æ–ª–æ–≤–∫–∏
                headers = df_original.columns.tolist()
                f.write("| " + " | ".join(headers) + " |\n")
                f.write("| " + " | ".join(["---"] * len(headers)) + " |\n")

                # –î–∞–Ω–Ω—ã–µ
                for _, row in df_original.iterrows():
                    row_data = []
                    for column in headers:
                        value = row[column] if pd.notna(row[column]) else ""
                        # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã Markdown, –ø–µ—Ä–µ–Ω–æ—Å—ã –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ <br>
                        value = str(value).replace("|", "\\|").replace("\n", "<br>")
                        row_data.append(value)
                    f.write("| " + " | ".join(row_data) + " |\n")

        print(f"üìù Markdown —Å–æ—Ö—Ä–∞–Ω–µ–Ω: markdown/{filename}")

        # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.stats["files_created"].append(
            {
                "format": "md",
                "filename": f"markdown/{filename}",
                "size_bytes": os.path.getsize(filepath),
            }
        )

    def save_html(
        self,
        df: pd.DataFrame,
        df_original: pd.DataFrame,
        sheet_name: str,
        page_num: int,
    ):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç DataFrame –≤ HTML"""
        if "html" not in self.enabled_formats:
            return

        clean_name = self.clean_filename(sheet_name)
        filename = f"{clean_name}_page_{page_num:02d}.html"
        filepath = os.path.join(self.output_dir, "html", filename)

        # –°–æ–∑–¥–∞–µ–º HTML —Å –∫—Ä–∞—Å–∏–≤—ã–º —Å—Ç–∏–ª–µ–º
        html_content = f"""
<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{sheet_name} - –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }}
        .container {{
            background: white;
            border-radius: 10px;
            padding: 30px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
        h1 {{
            color: #333;
            border-bottom: 3px solid #007bff;
            padding-bottom: 10px;
        }}
        table {{
            width: 100%;
            border-collapse: collapse;
            margin-top: 20px;
        }}
        th, td {{
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
            vertical-align: top;
        }}
        th {{
            background-color: #007bff;
            color: white;
            font-weight: bold;
        }}
        tr:nth-child(even) {{
            background-color: #f9f9f9;
        }}
        tr:hover {{
            background-color: #f5f5f5;
        }}
        .meta {{
            color: #666;
            font-style: italic;
            margin-bottom: 20px;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>üìã {sheet_name} - –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}</h1>
        <div class="meta">–°–æ–∑–¥–∞–Ω–æ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</div>

        <table>
"""

        if not df_original.empty:
            # –ó–∞–≥–æ–ª–æ–≤–∫–∏
            html_content += "            <thead><tr>\n"
            for column in df_original.columns:
                html_content += f"                <th>{column}</th>\n"
            html_content += "            </tr></thead>\n            <tbody>\n"

            # –î–∞–Ω–Ω—ã–µ
            for _, row in df_original.iterrows():
                html_content += "                <tr>\n"
                for column in df_original.columns:
                    value = row[column] if pd.notna(row[column]) else ""
                    # –ó–∞–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã –Ω–∞ <br> –¥–ª—è HTML
                    value = str(value).replace("\n", "<br>")
                    html_content += f"                    <td>{value}</td>\n"
                html_content += "                </tr>\n"

            html_content += "            </tbody>\n"

        html_content += """        </table>
    </div>
</body>
</html>"""

        with open(filepath, "w", encoding="utf-8") as f:
            f.write(html_content)

        print(f"üåê HTML —Å–æ—Ö—Ä–∞–Ω–µ–Ω: html/{filename}")

        # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.stats["files_created"].append(
            {
                "format": "html",
                "filename": f"html/{filename}",
                "size_bytes": os.path.getsize(filepath),
            }
        )

    def save_yaml(self, df: pd.DataFrame, sheet_name: str, page_num: int):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç DataFrame –≤ YAML"""
        if "yaml" not in self.enabled_formats:
            return

        clean_name = self.clean_filename(sheet_name)
        filename = f"{clean_name}_page_{page_num:02d}.yml"
        filepath = os.path.join(self.output_dir, "yaml", filename)

        data = {
            "sheet_info": {
                "name": sheet_name,
                "page": page_num,
                "created": datetime.now().isoformat(),
                "rows_count": len(df),
            },
            "data": df.to_dict("records"),
        }

        with open(filepath, "w", encoding="utf-8") as f:
            yaml.dump(data, f, default_flow_style=False, allow_unicode=True, indent=2)

        print(f"‚öôÔ∏è YAML —Å–æ—Ö—Ä–∞–Ω–µ–Ω: yaml/{filename}")

        # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.stats["files_created"].append(
            {
                "format": "yaml",
                "filename": f"yaml/{filename}",
                "size_bytes": os.path.getsize(filepath),
            }
        )

    def save_all_formats(
        self,
        df_processed: pd.DataFrame,
        df_original: pd.DataFrame,
        sheet_name: str,
        page_num: int,
    ):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤–æ –≤—Å–µ—Ö –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö"""
        self.save_csv(df_processed, sheet_name, page_num)
        self.save_json(df_processed, sheet_name, page_num)
        self.save_txt(df_processed, df_original, sheet_name, page_num)
        self.save_xlsx(df_processed, sheet_name, page_num)
        self.save_markdown(df_processed, df_original, sheet_name, page_num)
        self.save_html(df_processed, df_original, sheet_name, page_num)
        self.save_yaml(df_processed, sheet_name, page_num)

    def save_stats_report(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫—Ä–∞—Å–∏–≤—ã–π –æ—Ç—á–µ—Ç –æ –ø—Ä–æ–≤–µ–¥–µ–Ω–Ω–æ–π –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏"""
        self.stats["end_time"] = datetime.now()
        duration = self.stats["end_time"] - self.stats["start_time"]

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –ø–æ —Ñ–æ—Ä–º–∞—Ç–∞–º
        files_by_format = {}
        total_size = 0

        for file_info in self.stats["files_created"]:
            format_name = file_info["format"]
            if format_name not in files_by_format:
                files_by_format[format_name] = {
                    "count": 0,
                    "total_size": 0,
                    "files": [],
                }

            files_by_format[format_name]["count"] += 1
            files_by_format[format_name]["total_size"] += file_info["size_bytes"]
            files_by_format[format_name]["files"].append(file_info["filename"])
            total_size += file_info["size_bytes"]

        # –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞
        def format_size(size_bytes):
            if size_bytes < 1024:
                return f"{size_bytes} B"
            elif size_bytes < 1024 * 1024:
                return f"{size_bytes / 1024:.1f} KB"
            else:
                return f"{size_bytes / (1024 * 1024):.1f} MB"

        # –°–æ–∑–¥–∞–µ–º –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç
        report = {
            "üéâ –û–¢–ß–ï–¢ –û –ö–û–ù–í–ï–†–¢–ê–¶–ò–ò": {
                "üìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞": {
                    "–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è": self.stats["start_time"].strftime(
                        "%Y-%m-%d %H:%M:%S"
                    ),
                    "–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è": str(duration).split(".")[0],
                    "–í—Å–µ–≥–æ –ª–∏—Å—Ç–æ–≤ –Ω–∞–π–¥–µ–Ω–æ": self.stats["total_sheets"],
                    "–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ": self.stats["processed_sheets"],
                    "–ü—Ä–æ–ø—É—â–µ–Ω–æ": self.stats["skipped_sheets"],
                    "–ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞": f"{(self.stats['processed_sheets'] / max(self.stats['total_sheets'], 1) * 100):.1f}%",
                },
                "‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏": {
                    "–§–æ—Ä–º–∞—Ç—ã —ç–∫—Å–ø–æ—Ä—Ç–∞": self.stats["formats_used"],
                    "–¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π": (
                        "‚úÖ –í–∫–ª—é—á–µ–Ω–∞"
                        if self.stats["transliteration_enabled"]
                        else "‚ùå –û—Ç–∫–ª—é—á–µ–Ω–∞"
                    ),
                    "–í—Å–µ–≥–æ —Ñ–æ—Ä–º–∞—Ç–æ–≤": len(self.stats["formats_used"]),
                },
                "üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ —Ñ–æ—Ä–º–∞—Ç–∞–º": {},
                "üìã –î–µ—Ç–∞–ª–∏ –ø–æ –ª–∏—Å—Ç–∞–º": [],
                "üìÇ –°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã": files_by_format,
                "üíæ –†–∞–∑–º–µ—Ä—ã —Ñ–∞–π–ª–æ–≤": {
                    "–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä": format_size(total_size),
                    "–ü–æ —Ñ–æ—Ä–º–∞—Ç–∞–º": {
                        format_name: format_size(info["total_size"])
                        for format_name, info in files_by_format.items()
                    },
                },
                "üìà –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å": {
                    "–§–∞–π–ª–æ–≤ —Å–æ–∑–¥–∞–Ω–æ": len(self.stats["files_created"]),
                    "–°–∫–æ—Ä–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏": f"{self.stats['processed_sheets'] / max(duration.total_seconds(), 1):.2f} –ª–∏—Å—Ç–æ–≤/—Å–µ–∫",
                    "–°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞": format_size(
                        total_size / max(len(self.stats["files_created"]), 1)
                    ),
                },
            }
        }

        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ —Ñ–æ—Ä–º–∞—Ç–∞–º
        for format_name, info in files_by_format.items():
            format_display = self.available_formats.get(format_name, {}).get(
                "name", format_name
            )
            report["üéâ –û–¢–ß–ï–¢ –û –ö–û–ù–í–ï–†–¢–ê–¶–ò–ò"]["üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ —Ñ–æ—Ä–º–∞—Ç–∞–º"][
                format_display
            ] = {
                "–§–∞–π–ª–æ–≤ —Å–æ–∑–¥–∞–Ω–æ": info["count"],
                "–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä": format_size(info["total_size"]),
                "–°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä": format_size(
                    info["total_size"] / max(info["count"], 1)
                ),
            }

        # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ç–∞–ª–∏ –ø–æ –ª–∏—Å—Ç–∞–º
        for sheet_detail in self.stats["sheets_details"]:
            report["üéâ –û–¢–ß–ï–¢ –û –ö–û–ù–í–ï–†–¢–ê–¶–ò–ò"]["üìã –î–µ—Ç–∞–ª–∏ –ø–æ –ª–∏—Å—Ç–∞–º"].append(
                {
                    "–ù–∞–∑–≤–∞–Ω–∏–µ": sheet_detail["name"],
                    "–°—Ç–∞—Ç—É—Å": (
                        "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω" if sheet_detail["processed"] else "‚ùå –ü—Ä–æ–ø—É—â–µ–Ω"
                    ),
                    "–°—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö": sheet_detail.get("rows", 0),
                    "–ö–æ–ª–æ–Ω–æ–∫": sheet_detail.get("columns", 0),
                    "–ü—Ä–∏—á–∏–Ω–∞ –ø—Ä–æ–ø—É—Å–∫–∞": sheet_detail.get("skip_reason", ""),
                }
            )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        stats_filepath = os.path.join(self.output_dir, "stats.json")
        with open(stats_filepath, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=4, default=str)

        print(f"\nüìä –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: stats.json")

        # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É
        print("\n" + "=" * 60)
        print("üìä –ö–†–ê–¢–ö–ê–Ø –°–í–û–î–ö–ê")
        print("=" * 60)
        print(f"‚è±Ô∏è  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {str(duration).split('.')[0]}")
        print(
            f"üìÑ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ª–∏—Å—Ç–æ–≤: {self.stats['processed_sheets']}/{self.stats['total_sheets']}"
        )
        print(f"üìÅ –°–æ–∑–¥–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(self.stats['files_created'])}")
        print(f"üíæ –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {format_size(total_size)}")
        print(f"üéØ –§–æ—Ä–º–∞—Ç—ã: {', '.join(self.stats['formats_used'])}")

        return report

    def convert_all_sheets(self, url: str) -> bool:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Ç–∞–±–ª–∏—Ü—ã"""
        try:
            # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            self.create_output_directories()

            # –ò–∑–≤–ª–µ–∫–∞–µ–º ID —Ç–∞–±–ª–∏—Ü—ã
            sheet_id = self.extract_sheet_id(url)
            print(f"üîç ID —Ç–∞–±–ª–∏—Ü—ã: {sheet_id}")

            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö —á–µ—Ä–µ–∑ API
            sheets_info = self.get_all_sheets_info(sheet_id)

            if not sheets_info:
                print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                return False

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            processed_count = 0
            skipped_count = 0

            print("\n" + "=" * 50)
            print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Å—Ç—Ä–∞–Ω–∏—Ü")
            print("=" * 50)

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
            for page_num, sheet_info in enumerate(sheets_info, 1):
                gid = sheet_info["gid"]
                sheet_name = sheet_info["name"]

                print(f"\nüìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É {page_num}: '{sheet_name}'")
                print("-" * 30)

                # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                df_original, load_success = self.load_sheet_data(
                    sheet_id, gid, sheet_name
                )

                if not load_success or df_original.empty:
                    print(f"‚è≠Ô∏è [{sheet_name}] –ü—Ä–æ–ø—É—Å–∫–∞–µ–º - –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
                    skipped_count += 1
                    # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                    self.stats["sheets_details"].append(
                        {
                            "name": sheet_name,
                            "processed": False,
                            "skip_reason": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö",
                        }
                    )
                    continue

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è (—Ç–µ–ø–µ—Ä—å —Ç–æ–ª—å–∫–æ –æ—á–∏—Å—Ç–∫–∞, –±–µ–∑ –∑–∞–º–µ–Ω—ã –ø–µ—Ä–µ–Ω–æ—Å–æ–≤)
                df_processed = self.process_text_fields(df_original)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Å–µ—Ö –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö (–∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–¥–Ω–∏ –∏ —Ç–µ –∂–µ –¥–∞–Ω–Ω—ã–µ)
                self.save_all_formats(df_processed, df_processed, sheet_name, page_num)

                processed_count += 1
                print(f"‚úÖ [{sheet_name}] –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

                # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                self.stats["sheets_details"].append(
                    {
                        "name": sheet_name,
                        "processed": True,
                        "rows": len(df_original),
                        "columns": len(df_original.columns),
                    }
                )

            # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self.stats["total_sheets"] = len(sheets_info)
            self.stats["processed_sheets"] = processed_count
            self.stats["skipped_sheets"] = skipped_count

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
            try:
                self.save_stats_report()
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {e}")
                # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –æ—Ç—á–µ—Ç–∞

            # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
            print("\n" + "=" * 50)
            print("üìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢")
            print("=" * 50)
            print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_count} —Å—Ç—Ä–∞–Ω–∏—Ü")
            print(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ: {skipped_count} —Å—Ç—Ä–∞–Ω–∏—Ü")
            print(f"üìÅ –§–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {self.output_dir}/")

            if processed_count > 0:
                print("\nüéâ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
                return True
            else:
                print("\nüí• –ù–∏ –æ–¥–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –±—ã–ª–∞ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞")
                return False

        except Exception as e:
            print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            import traceback

            print("–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏:")
            traceback.print_exc()
            return False


def select_formats_interactive():
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä —Ñ–æ—Ä–º–∞—Ç–æ–≤"""
    available_formats = {
        "csv": "CSV —Ñ–∞–π–ª—ã (–¥–ª—è –ø–∞—Ä—Å–µ—Ä–æ–≤)",
        "json": "JSON —Ñ–∞–π–ª—ã (—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)",
        "txt": "TXT —Ñ–∞–π–ª—ã (–¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞)",
        "xlsx": "Excel —Ñ–∞–π–ª—ã (—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)",
        "md": "Markdown –¥–æ–∫—É–º–µ–Ω—Ç—ã (–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è)",
        "html": "HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–±—Ä–∞—É–∑–µ—Ä)",
        "yaml": "YAML –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (DevOps)",
    }

    print("\nüìã –í—ã–±–µ—Ä–∏—Ç–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è:")
    format_keys = list(available_formats.keys())

    for i, (key, desc) in enumerate(available_formats.items(), 1):
        print(f"  {i}. {desc}")

    print("\nüìù –í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä–∞ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é (–Ω–∞–ø—Ä–∏–º–µ—Ä: 1,2,3) –∏–ª–∏ 'all' –¥–ª—è –≤—Å–µ—Ö:")
    choice = input("–í—ã–±–æ—Ä: ").strip()

    selected_formats = []

    if choice.lower() == "all":
        selected_formats = list(available_formats.keys())
        print("‚úÖ –í—ã–±—Ä–∞–Ω—ã –≤—Å–µ —Ñ–æ—Ä–º–∞—Ç—ã")
    else:
        try:
            indices = [int(x.strip()) for x in choice.split(",")]
            for idx in indices:
                if 1 <= idx <= len(format_keys):
                    selected_formats.append(format_keys[idx - 1])
                else:
                    print(f"‚ö†Ô∏è –ù–µ–≤–µ—Ä–Ω—ã–π –Ω–æ–º–µ—Ä: {idx}")

            if selected_formats:
                format_names = [available_formats[f] for f in selected_formats]
                print(f"‚úÖ –í—ã–±—Ä–∞–Ω—ã —Ñ–æ—Ä–º–∞—Ç—ã: {', '.join(format_names)}")
            else:
                print("‚ö†Ô∏è –ù–µ –≤—ã–±—Ä–∞–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–µ")
                selected_formats = ["csv", "json", "txt"]

        except ValueError:
            print("‚ö†Ô∏è –ù–µ–≤–µ—Ä–Ω—ã–π –≤–≤–æ–¥, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã")
            selected_formats = ["csv", "json", "txt"]

    # –í—ã–±–æ—Ä —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏
    print("\nüî§ –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è —Ä—É—Å—Å–∫–∏—Ö –Ω–∞–∑–≤–∞–Ω–∏–π —Ñ–∞–π–ª–æ–≤ –≤ –ª–∞—Ç–∏–Ω–∏—Ü—É?")
    print("  (–≤–∏–∑–∏—Ç–∫–∏ ‚Üí vizitki)")
    transliterate_choice = input("–¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä–æ–≤–∞—Ç—å? (y/n): ").strip().lower()
    transliterate = transliterate_choice in ["y", "yes", "–¥", "–¥–∞", "1"]

    if transliterate:
        print("‚úÖ –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è –≤–∫–ª—é—á–µ–Ω–∞")
    else:
        print("‚úÖ –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤")

    return selected_formats, transliterate


def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –≤ –ø—Ä–æ–≥—Ä–∞–º–º—É"""
    print("üìã Universal Google Sheets to Multiple Formats Converter")
    print("=" * 60)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    if len(sys.argv) >= 2:
        # CLI —Ä–µ–∂–∏–º
        url = sys.argv[1]
        print("üöÄ –ó–∞–ø—É—Å–∫ –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞ (CLI —Ä–µ–∂–∏–º)")
        print(f"üìã URL: {url}")
        print("=" * 70)

        # –í CLI —Ä–µ–∂–∏–º–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ —Ñ–æ—Ä–º–∞—Ç—ã —Å —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–µ–π (–±–µ–∑ PDF)
        converter = UniversalSheetsConverter(
            formats=["csv", "json", "txt", "xlsx", "md", "html", "yaml"],
            transliterate=True,
        )

        success = converter.convert_all_sheets(url)

        if success:
            print("\nüéâ –ü—Ä–æ–≥—Ä–∞–º–º–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        else:
            print("\nüí• –ü—Ä–æ–≥—Ä–∞–º–º–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–∞–º–∏.")
            sys.exit(1)
    else:
        # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º
        print("üîß –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º")
        print(f"\nüß™ –¢–µ—Å—Ç–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞: {URL_TEST}")
        print("-" * 60)

        while True:
            try:
                print("\n1. –í–≤–µ—Å—Ç–∏ URL —Ç–∞–±–ª–∏—Ü—ã (—Å –≤—ã–±–æ—Ä–æ–º —Ñ–æ—Ä–º–∞—Ç–æ–≤)")
                print("2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É (–≤—Å–µ —Ñ–æ—Ä–º–∞—Ç—ã)")
                print("3. –í—ã—Ö–æ–¥")

                choice = input("\nüìù –í—ã–±–µ—Ä–∏—Ç–µ –æ–ø—Ü–∏—é (1-3): ").strip()

                if choice == "1":
                    url = input("\nüìù –í–≤–µ–¥–∏—Ç–µ URL Google –¢–∞–±–ª–∏—Ü—ã: ").strip()

                    if not url:
                        print("‚ö†Ô∏è –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞. –í–≤–µ–¥–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL.")
                        continue

                    if "docs.google.com/spreadsheets" not in url:
                        print(
                            "‚ö†Ô∏è –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL. –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 'docs.google.com/spreadsheets'"
                        )
                        continue

                    # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä —Ñ–æ—Ä–º–∞—Ç–æ–≤
                    formats, transliterate = select_formats_interactive()
                    converter = UniversalSheetsConverter(
                        formats=formats, transliterate=transliterate
                    )

                elif choice == "2":
                    url = URL_TEST
                    print(f"üìù –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ—Å—Ç–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É: {url}")

                    # –í—Å–µ —Ñ–æ—Ä–º–∞—Ç—ã —Å —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–µ–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–±–µ–∑ PDF)
                    converter = UniversalSheetsConverter(
                        formats=["csv", "json", "txt", "xlsx", "md", "html", "yaml"],
                        transliterate=True,
                    )

                elif choice in ["3", "exit", "quit", "–≤—ã—Ö–æ–¥"]:
                    print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
                    break

                else:
                    print("‚ö†Ô∏è –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä. –í–≤–µ–¥–∏—Ç–µ 1, 2 –∏–ª–∏ 3.")
                    continue

                print("\nüöÄ –ó–∞–ø—É—Å–∫ –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞ (–∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º)")
                print(f"üìã URL: {url}")
                print("=" * 70)

                success = converter.convert_all_sheets(url)

                if success:
                    print("\nüéâ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
                else:
                    print("\nüí• –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–∞–º–∏.")

                # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –µ—â–µ –æ–¥–Ω—É —Ç–∞–±–ª–∏—Ü—É
                while True:
                    continue_choice = (
                        input("\n‚ùì –•–æ—Ç–∏—Ç–µ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –µ—â–µ –æ–¥–Ω—É —Ç–∞–±–ª–∏—Ü—É? (y/n): ")
                        .strip()
                        .lower()
                    )
                    if continue_choice in ["y", "yes", "–¥", "–¥–∞"]:
                        break
                    elif continue_choice in ["n", "no", "–Ω", "–Ω–µ—Ç"]:
                        print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
                        return
                    else:
                        print("‚ö†Ô∏è –í–≤–µ–¥–∏—Ç–µ 'y' –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –∏–ª–∏ 'n' –¥–ª—è –≤—ã—Ö–æ–¥–∞")

            except KeyboardInterrupt:
                print("\n\nüëã –ü—Ä–æ–≥—Ä–∞–º–º–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º. –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
                break
            except Exception as e:
                print(f"\n‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
                print("–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –≤–≤–µ–¥–∏—Ç–µ '3' –¥–ª—è –≤—ã—Ö–æ–¥–∞.")


if __name__ == "__main__":
    main()
